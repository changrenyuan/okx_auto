"""
ä¸‰çº§å­˜å‚¨ (Cold Storage)
é«˜æ€§èƒ½æ—¶åºæ–‡ä»¶ï¼Œç”¨äºå†å²æ•°æ®å’Œå›æµ‹

ä½¿ç”¨ HDF5/Parquet å®ç°ï¼š
- å†å²ç›˜å£æ•°æ®
- æˆäº¤æ—¥å¿—
- ç”¨äºå›æµ‹å’Œç­–ç•¥ä¼˜åŒ–
"""

import pandas as pd
from typing import Dict, List, Optional
from datetime import datetime
from pathlib import Path

try:
    import pyarrow as pa
    import pyarrow.parquet as pq
    PARQUET_AVAILABLE = True
except ImportError:
    PARQUET_AVAILABLE = False

try:
    import h5py
    HDF5_AVAILABLE = True
except ImportError:
    HDF5_AVAILABLE = False

from utils.logger import logger


class ColdStorageLayer:
    """
    ä¸‰çº§å­˜å‚¨å±‚ - å†å²æ•°æ®å­˜å‚¨
    
    ç‰¹æ€§ï¼š
    - åˆ—å¼å­˜å‚¨ï¼Œå¿«é€Ÿè¯»å–
    - æ”¯æŒæ—¶é—´èŒƒå›´æŸ¥è¯¢
    - æ•°æ®å‹ç¼©
    - é€‚åˆå›æµ‹å’Œç­–ç•¥ä¼˜åŒ–
    """
    
    def __init__(
        self,
        data_dir: str = "data/historical",
        format: str = "parquet"  # parquet æˆ– hdf5
    ):
        """
        åˆå§‹åŒ–ä¸‰çº§å­˜å‚¨
        
        Args:
            data_dir: æ•°æ®ç›®å½•
            format: å­˜å‚¨æ ¼å¼ (parquet/hdf5)
        """
        self.data_dir = Path(data_dir)
        self.format = format.lower()
        
        # åˆ›å»ºæ•°æ®ç›®å½•
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # æ£€æŸ¥å¯ç”¨æ€§
        if self.format == "parquet" and not PARQUET_AVAILABLE:
            logger.warning("âš ï¸  Parquet ä¸å¯ç”¨ï¼Œä½¿ç”¨ HDF5")
            self.format = "hdf5"
        elif self.format == "hdf5" and not HDF5_AVAILABLE:
            logger.warning("âš ï¸  HDF5 ä¸å¯ç”¨ï¼Œä½¿ç”¨ Parquet")
            self.format = "parquet"
        
        logger.info(f"ğŸ§Š ä¸‰çº§å­˜å‚¨åˆå§‹åŒ–å®Œæˆ | æ ¼å¼: {self.format} | ç›®å½•: {self.data_dir}")
    
    def _get_file_path(self, inst_id: str, date: str, data_type: str) -> Path:
        """
        è·å–æ–‡ä»¶è·¯å¾„
        
        Args:
            inst_id: äº§å“ ID
            date: æ—¥æœŸ (YYYY-MM-DD)
            data_type: æ•°æ®ç±»å‹ (orderbook/trades/ohlcv)
        
        Returns:
            æ–‡ä»¶è·¯å¾„
        """
        filename = f"{inst_id}_{date}_{data_type}.{self.format}"
        return self.data_dir / filename
    
    # ========== Order Book å¿«ç…§ ==========
    
    def save_orderbook_snapshot(
        self,
        inst_id: str,
        timestamp: datetime,
        bids: List[tuple],
        asks: List[tuple]
    ):
        """
        ä¿å­˜ Order Book å¿«ç…§
        
        Args:
            inst_id: äº§å“ ID
            timestamp: æ—¶é—´æˆ³
            bids: [(ä»·æ ¼, æ•°é‡), ...]
            asks: [(ä»·æ ¼, æ•°é‡), ...]
        """
        try:
            date_str = timestamp.strftime("%Y-%m-%d")
            file_path = self._get_file_path(inst_id, date_str, "orderbook")
            
            # æ„é€  DataFrame
            data = []
            
            # ä¹°ç›˜
            for price, size in bids:
                data.append({
                    "timestamp": timestamp,
                    "side": "bid",
                    "price": price,
                    "size": size,
                    "inst_id": inst_id
                })
            
            # å–ç›˜
            for price, size in asks:
                data.append({
                    "timestamp": timestamp,
                    "side": "ask",
                    "price": price,
                    "size": size,
                    "inst_id": inst_id
                })
            
            df = pd.DataFrame(data)
            
            # ä¿å­˜
            self._save_dataframe(df, file_path)
        
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ Order Book å¿«ç…§å¤±è´¥: {e}")
    
    def load_orderbook_snapshot(
        self,
        inst_id: str,
        date: str,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None
    ) -> pd.DataFrame:
        """
        åŠ è½½ Order Book å¿«ç…§
        
        Args:
            inst_id: äº§å“ ID
            date: æ—¥æœŸ (YYYY-MM-DD)
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
        
        Returns:
            DataFrame
        """
        try:
            file_path = self._get_file_path(inst_id, date, "orderbook")
            
            if not file_path.exists():
                logger.warning(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return pd.DataFrame()
            
            df = self._load_dataframe(file_path)
            
            # æ—¶é—´è¿‡æ»¤
            if start_time or end_time:
                if "timestamp" in df.columns:
                    df["timestamp"] = pd.to_datetime(df["timestamp"])
                    
                    if start_time:
                        df = df[df["timestamp"] >= start_time]
                    
                    if end_time:
                        df = df[df["timestamp"] <= end_time]
            
            return df
        
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ Order Book å¿«ç…§å¤±è´¥: {e}")
            return pd.DataFrame()
    
    # ========== æˆäº¤æ•°æ® ==========
    
    def save_trades(
        self,
        inst_id: str,
        trades: List[dict]
    ):
        """
        ä¿å­˜æˆäº¤æ•°æ®
        
        Args:
            inst_id: äº§å“ ID
            trades: [æˆäº¤æ•°æ®, ...]
                æ¯ä¸ªæˆäº¤æ•°æ®åŒ…å«: price, size, side, timestamp, trade_id
        """
        try:
            if not trades:
                return
            
            # æŒ‰æ—¥æœŸåˆ†ç»„
            trades_by_date = {}
            
            for trade in trades:
                timestamp = trade.get("timestamp")
                if isinstance(timestamp, str):
                    timestamp = pd.to_datetime(timestamp)
                elif isinstance(timestamp, (int, float)):
                    # Unix æ—¶é—´æˆ³è½¬æ¢ä¸º datetime
                    timestamp = pd.to_datetime(timestamp, unit='ms')
                
                if timestamp is None:
                    continue
                
                date_str = timestamp.strftime("%Y-%m-%d")
                
                if date_str not in trades_by_date:
                    trades_by_date[date_str] = []
                
                trades_by_date[date_str].append(trade)
            
            # ä¿å­˜æ¯ä¸ªæ—¥æœŸçš„æ•°æ®
            for date_str, daily_trades in trades_by_date.items():
                df = pd.DataFrame(daily_trades)
                file_path = self._get_file_path(inst_id, date_str, "trades")
                
                self._save_dataframe(df, file_path)
            
            logger.info(f"ğŸ’¾ ä¿å­˜æˆäº¤æ•°æ®: {inst_id} | {len(trades)} ç¬”")
        
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æˆäº¤æ•°æ®å¤±è´¥: {e}")
    
    def load_trades(
        self,
        inst_id: str,
        start_date: str,
        end_date: str
    ) -> pd.DataFrame:
        """
        åŠ è½½æˆäº¤æ•°æ®
        
        Args:
            inst_id: äº§å“ ID
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        
        Returns:
            DataFrame
        """
        try:
            all_data = []
            
            current_date = pd.to_datetime(start_date)
            end_datetime = pd.to_datetime(end_date)
            
            while current_date <= end_datetime:
                date_str = current_date.strftime("%Y-%m-%d")
                file_path = self._get_file_path(inst_id, date_str, "trades")
                
                if file_path.exists():
                    df = self._load_dataframe(file_path)
                    all_data.append(df)
                
                current_date += pd.Timedelta(days=1)
            
            if all_data:
                return pd.concat(all_data, ignore_index=True)
            else:
                return pd.DataFrame()
        
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æˆäº¤æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    # ========== OHLCV æ•°æ® ==========
    
    def save_ohlcv(
        self,
        inst_id: str,
        ohlcv_data: pd.DataFrame
    ):
        """
        ä¿å­˜ OHLCV æ•°æ®
        
        Args:
            inst_id: äº§å“ ID
            ohlcv_data: OHLCV DataFrame
                columns: timestamp, open, high, low, close, volume
        """
        try:
            if ohlcv_data.empty:
                return
            
            # æŒ‰æ—¥æœŸåˆ†ç»„ä¿å­˜
            ohlcv_data["timestamp"] = pd.to_datetime(ohlcv_data["timestamp"])
            ohlcv_data["date"] = ohlcv_data["timestamp"].dt.date
            
            for date, group in ohlcv_data.groupby("date"):
                date_str = date.strftime("%Y-%m-%d")
                file_path = self._get_file_path(inst_id, date_str, "ohlcv")
                
                group = group.drop(columns=["date"])
                self._save_dataframe(group, file_path)
            
            logger.info(f"ğŸ’¾ ä¿å­˜ OHLCV æ•°æ®: {inst_id} | {len(ohlcv_data)} æ¡")
        
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ OHLCV æ•°æ®å¤±è´¥: {e}")
    
    def load_ohlcv(
        self,
        inst_id: str,
        start_date: str,
        end_date: str
    ) -> pd.DataFrame:
        """
        åŠ è½½ OHLCV æ•°æ®
        
        Args:
            inst_id: äº§å“ ID
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        
        Returns:
            DataFrame
        """
        try:
            all_data = []
            
            current_date = pd.to_datetime(start_date)
            end_datetime = pd.to_datetime(end_date)
            
            while current_date <= end_datetime:
                date_str = current_date.strftime("%Y-%m-%d")
                file_path = self._get_file_path(inst_id, date_str, "ohlcv")
                
                if file_path.exists():
                    df = self._load_dataframe(file_path)
                    all_data.append(df)
                
                current_date += pd.Timedelta(days=1)
            
            if all_data:
                return pd.concat(all_data, ignore_index=True).sort_values("timestamp")
            else:
                return pd.DataFrame()
        
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ OHLCV æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    # ========== åº•å±‚å­˜å‚¨æ“ä½œ ==========
    
    def _save_dataframe(self, df: pd.DataFrame, file_path: Path):
        """
        ä¿å­˜ DataFrame
        
        Args:
            df: DataFrame
            file_path: æ–‡ä»¶è·¯å¾„
        """
        if self.format == "parquet":
            df.to_parquet(file_path, index=False, compression="snappy")
        else:  # hdf5
            # HDF5 æ¨¡å¼
            df.to_hdf(file_path, key="data", mode="a", complevel=9, complib="blosc")
    
    def _load_dataframe(self, file_path: Path) -> pd.DataFrame:
        """
        åŠ è½½ DataFrame
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
        
        Returns:
            DataFrame
        """
        if self.format == "parquet":
            return pd.read_parquet(file_path)
        else:  # hdf5
            return pd.read_hdf(file_path, key="data")
    
    # ========== æ•°æ®ç®¡ç† ==========
    
    def get_available_dates(self, inst_id: str, data_type: str) -> List[str]:
        """
        è·å–å¯ç”¨çš„æ—¥æœŸåˆ—è¡¨
        
        Args:
            inst_id: äº§å“ ID
            data_type: æ•°æ®ç±»å‹
        
        Returns:
            æ—¥æœŸåˆ—è¡¨
        """
        pattern = f"{inst_id}_*_{data_type}.{self.format}"
        files = list(self.data_dir.glob(pattern))
        
        dates = []
        for file in files:
            parts = file.stem.split("_")
            if len(parts) >= 2:
                dates.append(parts[1])
        
        return sorted(dates)
    
    def delete_data(self, inst_id: str, date: str, data_type: str):
        """
        åˆ é™¤æ•°æ®
        
        Args:
            inst_id: äº§å“ ID
            date: æ—¥æœŸ (YYYY-MM-DD)
            data_type: æ•°æ®ç±»å‹
        """
        try:
            file_path = self._get_file_path(inst_id, date, data_type)
            
            if file_path.exists():
                file_path.unlink()
                logger.info(f"ğŸ—‘ï¸  åˆ é™¤æ•°æ®: {file_path}")
            else:
                logger.warning(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤æ•°æ®å¤±è´¥: {e}")
    
    def get_storage_size(self) -> Dict[str, int]:
        """
        è·å–å­˜å‚¨å¤§å°
        
        Returns:
            {data_type: size_bytes}
        """
        try:
            sizes = {}
            
            for file in self.data_dir.glob(f"*.{self.format}"):
                data_type = file.stem.split("_")[-1]
                size = file.stat().st_size
                
                if data_type not in sizes:
                    sizes[data_type] = 0
                
                sizes[data_type] += size
            
            return sizes
        
        except Exception as e:
            logger.error(f"âŒ è·å–å­˜å‚¨å¤§å°å¤±è´¥: {e}")
            return {}
